---
title: "構造的因果モデルの基礎 輪読 ＃2"
subtitle: "第2章 準備"
author: "谷口友哉"
date: "`r format(Sys.time(),'%Y/%m/%d')`"
output:
  revealjs::revealjs_presentation:
    reveal_option:
      slideNumber: 'c/t'
      center: false
    #pandoc_args: [
    #  '--from', 'markdown+autolink_bare_uris+tex_math_single_backslash-implicit_figures'
    #]
    self_contained: true
    theme: sky
    css: "for-revealjs.css"
---

# 2.1 因果推論における確率的考え方

## 構造的因果モデルのフレームワーク
\newcommand{\indep}{\mathop{\,\perp\!\!\!\!\!\perp\,}}
\newcommand{\notindep}{\mathop{\,\perp\!\!\!\!\!/\!\!\!\!\!\perp\,}}
\newcommand{\mat}[1]{\begin{pmatrix} #1 \end{pmatrix}}

* 仮定
<div class="box">
データは何らかの物理的なデータ生成過程に  
従って生成
  * 変数間に客観的な関数関係（構造方程式モデル）が存在
  * 関数関係：「原因と呼ばれる変数に値を代入すると結果と  
  呼ばれる変数に1つの値が出力されるが、  
  結果に値を代入しても原因に対する値は得られない」
</div>
* 自然科学分野だけでなく、医学・工学・社会科学・  
人文科学的現象も議論の対象
* データ生成過程の存在を仮定  
➡︎直接的・間接的な因果関係や**共通原因の原理**を  
 確率モデルに反映させる第1ステップ

## 共通原因の原理（common cause principle）

<div class="box">
No correlation without causation  
因果なく相関なし
</div>
$\quad$
<div class="box">
If an improbable coincidence has occurred, there must exist a common cause (Reichenbach,1956,p.157)  
ありえない偶然の一致が起こった場合、  
共通の原因が存在しなければならない
</div>

## 因果関係の解明を拒む壁

* **不確実性**が存在
  * データが大量に得られても、そのデータから推測された  
  統計モデルが物理的なデータ生成過程を適切に記述したものであることを、データだけを用いて保証する術を我々が持たない
  * 本来決定論的に解明したい因果関係を決定論的に  
  評価することが困難
* 構造的因果モデルのフレームワークでは  
不確実性を評価するために、  
データ生成過程と確率・統計的な考え方が融合

# 2.2 事象の確率

## 試行と事象の定義

* 試行（trial）
<div class="box">
母集団からデータを採取するために行う実験や観測
</div>

* 確率試行（stochastic trial）
<div class="box">
データを採取する際、起こりうる結果の全体は  
概ね分かるが、その中のどれが観測できるのかを  
あらかじめ知ることができない実験や観測
</div>

* 標本空間（sample space）,全事象（certain event）
<div class="box">
確率試行を行った時に起こりうる結果（要素）の  
全体：$\Omega$ で表記
</div>

* 事象（event）
<div class="box">
標本空間の部分集合:  
A,B,C...のように大文字アルファベットで表記
</div>

## 事象の種類

<div class="box">
和事象（union of events）：$A\cup B$  
・事象A,Bの両方に含まれる要素を全て合わせたもの
</div>

<div class="box">
積事象（intersection of events）：$A\cap B$  
・事象A,Bの両方に含まれる要素全てからなる  
$\;\:\:$標本空間$\Omega$ の部分集合
</div>

<div class="box">
差事象（difference of events）：$A\backslash B$  
・事象Aから事象Bに含まれる要素全てを取り除いた後に  
$\;\:\:$残ったAの要素全体からなる集合
</div>

<div class="box">
余事象（complement of an events）：$A^{c}$  
・$\Omega\backslash A$ を意味する
</div>

<div class="box">
空集合（empty events）：$\phi$  
・$\Omega$ の要素を全く持たない集合
</div>

<div class="box">
排反（disjoint,exclusive）  
・$A\cap B$ が空集合である時
</div>

## 例題：事象

* 標本空間:a,b,c,dを要素とする$\Omega=\bigl\{a,b,c,d\bigr\}$
* $\Omega$ の部分集合$A=\bigl\{a,b\bigr\}$,$B=\bigl\{b,c\bigr\}$
* 和事象、積事象、差事象、余事象は

$$
A\cup B=\bigl\{a,b,c\bigr\},A\cap B=\bigl\{b\bigr\},\\
A\backslash B=\bigl\{a\bigr\},A^{c}=\bigl\{c,d\bigr\}
\tag{2.1}
$$

## 確率（probability）

<div class="box">
確率とは標本空間$\Omega$の部分集合で定義された関数$pr(\cdot)$ 
</div>

* ある事象Aが起こる（Aの要素が観測される）確率を$pr(A)$と表記
* 次の3つを満たす

$$
0\leq pr(A)\leq1,\quad A\subset \Omega\tag{2.2}
$$

$$
pr(\Omega)=1\tag{2.3}
$$

$$
A\cap B = \phi\Rightarrow pr(A\cup B) = pr(A) + pr(B) \tag{2.4}
$$

* 積事象$A\cap B,A\cap B^c$ は排反であることから、

$$
\begin{aligned}
pr(A) &=pr\bigl((A\cap B)\cup (A\cap B^c)\bigr)\\
&=pr(A\cap B) + pr(A\cap B^c) 
\end{aligned}
\tag{2.5}
$$

## 全確率の公式（law of total probability）

* より一般に、$B_i(i=1,\:_\cdots,n)$ を互いに排反で標本空間$\Omega$ を完全に分割する事象、つまり$\Omega = B_1\cup_\cdots\cup B_n$で  
かつ$i ≠j\:(i,j = 1,_\cdots,n)$ に対して積事象$B_i\cap B_j$ が  
空集合となる事象のある集まりとする。このとき

$$
\begin{aligned}
A &= A\cap\Omega\\
&= A\cap( B_1\cup_\cdots\cup B_n)\\
&= (A\cap B_1)\cup_\cdots\cup(A\cap B_n)
\end{aligned}
\tag{2.6}
$$

* つまり$pr(A)$は$pr(A\cap B_i)\:(i=1,_\cdots n)$ を用いて

$$
\begin{aligned}
pr(A) &= pr(A\cap\Omega)\\
&= pr\bigl((A\cap B_1)\cup_\cdots\cup(A\cap B_n)\bigr)\\
&= \sum_{i=1}^{n}pr(A\cap B_i)
\end{aligned}
\tag{2.7}
$$

* (2.7)式を**全確率の公式**という

## 周辺確率（marginal probability）

<div class="box">
(2.7)式において、積事象$A\cap B_i$ に対する確率$pr(A\cap B_i)$が与えられた時、全ての$B_i$ について確率を  
足し合わせることで得られる確率$pr(A)$ をAの**周辺確率**という
</div>

(cf) 事象$A$とその余事象$A^c$のどちらか1つは必ず起きることから(2.5)式の$A,B$ を$\Omega,A$と置き直すことにより、

$$
pr(A) + pr(A^c) = 1 \tag{2.8}
$$

## 条件付き確率（conditional probability）

<div class="box">
ある事象$B$ が起こるという条件の下でもう1つの事象$A$ が起こる確率：$pr(A|B)$
</div>

* $pr(B)>0$ であるとき、$pr(A|B)$を事象$B$ を与えた時の事象$A$ の条件付き確率という

$$
pr(A|B) = \frac{pr(A\cap B)}{pr(B)} \tag{2.9}
$$

## 乗法公式（product rule）{#2_2}



## 連鎖公式（chain rule）



## 事象の（周辺）独立性（(marginal) independence）

$$
A \indep B
$$


## 事象の条件付き独立性（conditional independence）



# 2.3 確率変数

## 離散型確率変数

$$
pr(X = x)\geq0,\quad\sum_{x}pr(X = x)=1\tag{2.19}
$$



## 連続型確率変数



## 期待値（expectation）



# 2.4 確率変数ベクトル

## 多次元確率変数ベクトルへ拡張


## 確率変数の集合



## 同時（確率）密度関数（joint probability density function）



## （累積）同時分布関数（joint cumulative distribution function）



## 周辺分布関数と周辺確率密度関数



## 条件付き確率密度関数（conditional probability density function）



## 乗法公式 {#2_4}



## 乗法公式の拡張 {#product_rule_Expansion}

* 逐次的因数分解（recursive factorization）,連鎖公式


## 確率変数どうしの（周辺）独立性


## 確率変数どうしの条件付き独立性


## 条件付き期待値と条件付き分散


## 共分散と条件付き共分散


## 相関係数と条件付き相関係数

* 線形構造方程式モデルにおいては  
偏相関係数（partial correlation coefficient）と呼ばれる

## 相関係数の基本的な性質


## 共分散行列、相関行列、相互共分散行列


# 2.5 グラフォイド原理

## グラフォイド原理（graphoid axioms）


## 条件付き独立関係のルール


## ルールを視覚化




# 2.6 グラフ用語

## 構造的因果モデルでグラフを使う意義

* 構造的因果モデルに基づいた因果推論では、必ずしも  
グラフを使わなければならないわけではない（第1.2節）
* パス解析が源泉
* 構造的因果モデルのフレームワークを構築した  
Judea Pearl本人がベイジアンネットワークの体系を構築
➡︎構造的因果モデルを扱った文献のほとんどで  
有向グラフによる解釈

## グラフ用語の定義

<div class="box">
グラフ $G$（graph）は頂点（vertex,node）集合 $\bf V$ と  
その直積集合$\bf V \times \bf V$の部分集合である矢線（arrow）  
あるいは有向辺（directed edge）の集合$\bf E$ によって、
$\bf G = (\bf V,\bf E)$ と表現される
</div>

## 割り当てられる矢線の種類

* 異なる2つの頂点 $\alpha,\beta\in \bf V$ $(\alpha \neq \beta)$ に対して、$(\alpha,\beta)$ と $(\beta,\alpha)$ を同一視し、$(\alpha,\beta) \in \bf E$ であるとき、以下の  
3つのうちの少なくとも1つを割り当てる  

1. $\alpha$ から $\beta$ への矢線: $\alpha \rightarrow \beta$
2. $\alpha$ と $\beta$ の双方向矢線（bidirected arrow）: $\alpha \leftrightarrow \beta$
3. $\beta$ から $\alpha$ への矢線: $\beta \rightarrow \alpha$

* ただし$(\alpha,\beta) \in \bf E$に割り当てられる矢線の数は最大で3つ
  * 同じタイプの矢線は割り当てない
  * $\alpha$ から $\alpha$ 自身に向かう矢線は考えない
  
## 部分グラフ（subgraph）

<div class="box">
頂点集合 $\bf V$ の部分集合$\bf V^*$と  
矢線の集合$\bf E$ の部分集合$\bf E^*$に対して、  
$\bf E^*$ に属する矢線の両端が $\bf V^*$ に属する時、  
グラフ $G^* = (\bf V^*,\bf E^*)$ を$\bf V^*$ から生成される  
$G$ の部分グラフという
</div>

## 親（parent）と子（child）

<div class="box">
* $\alpha$ から $\beta$ への矢線 $\alpha \rightarrow \beta$ が  存在する時、  
$\alpha$ は $\beta$ の親（先祖・非子孫）であるといい、  
$\beta$ は $\alpha$ の子（子孫）であるという
* $pa(\beta)$ : $\beta$ の親の集合
* $ch(\alpha)$ : $\alpha$ の子の集合
* 配偶者（spouse）: 双方向矢線が存在
* 根（root）,源点（source）: グラフ$\bf G$ の頂点でそれに向かう矢線がない
* 葉（leaf）,沈点（sink）: それから出る矢線を持たない
* 例　$\alpha \leftarrow \beta \rightarrow \gamma$ では  
  * $\beta$ は根、$\alpha,\gamma$ は葉
</div>

## 道（path）と有向道（directed path）

<div class="box">
* 異なる頂点の列 $\alpha_0,\alpha_1,\cdots,\alpha_n$ において全ての $i = 1,_\cdots,n$ で $(\alpha_{i-1},\alpha_i) \in \bf E$ であるとき、頂点の列 $\alpha_0,\alpha_1,\cdots,\alpha_n$ を  
$\alpha_0$ と $\alpha_n$ の間の**道**という  
このとき、$\alpha_0$ と $\alpha_n$ を**端点**（endpoint）という  
$\alpha_0$ と $\alpha_n$ の間に道があるとき$\alpha_0$ と $\alpha_n$ は**連結している**（connect）という  
* $\alpha_0$ と $\alpha_n$ の間の道において、全ての $i = 1,_\cdots,n$ に対して$\alpha_{i-1} \rightarrow \alpha_i$ であって $\alpha_i \rightarrow \alpha_{i-1}$ や $\alpha_i \leftrightarrow \alpha_{i-1}$でないとき、  
つまり

$$
\alpha_0 \rightarrow \alpha_1 \rightarrow \cdots \rightarrow\alpha_{n-1} \rightarrow \alpha_n\tag{2.52}
$$
$\;\;\:$を$\alpha_0$ から $\alpha_n$ への**有向道**という
</div>

## バックドアパス（back door path）

<div class="box">
* $\alpha_0$ と $\alpha_n$ の間の道で$\alpha_0$ へ向かう矢線を含むものを  
( $\alpha_0$ からの）**バックドアパス**という  
* 双方向矢線はバックドアパスの例の一つ
* 見方を変えれば、$\alpha_0$ から $\alpha_n$ への有向道も  
$\alpha_n$ からのバックドアパス
</div>

## 巡回閉路と非巡回有向グラフ

<div class="box">
* 有向道 $\alpha_0,\alpha_1,\cdots,\alpha_n$ で $\alpha_0 = \alpha_n$ を許す、つまり、

$$
\alpha_0 \rightarrow \alpha_1 \rightarrow \cdots \rightarrow\alpha_{n-1} \rightarrow \alpha_0 \tag{2.53}
$$

$\;\;\:$を**巡回閉路**（cycle）という  

* 巡回閉路の存在しない有効グラフを**非巡回的**（acyclic）といい、  
**非巡回的有向グラフ**（directed acyclic graph;**DAG**）と  
いう
</div>

## DAGで登場する用語1 {#DAG_1}

* $\alpha$ から $\beta$ へ有向道が存在する時

<div class="box">
* $\alpha$ は $\beta$ の**先祖**（ancestor）
* $\beta$ は $\alpha$ の**子孫**（descendant）
</div>

* $\alpha$ と $\beta$ が先祖と子孫の関係である時

<div class="box">
* $\alpha$ は $\beta$ よりも**上流**（upstream）にある
* $\beta$ は $\alpha$ よりも**下流**（downstream）にある
* $de(\alpha)$ を $\alpha$ の子孫からなる集合とした時、  
$\bf V$$\backslash \bigl(de(\alpha) \cup \{a\} \bigr)$ の要素を $\alpha$ の  
**非子孫**（non-descendant）
* $nd(\alpha)$ を$\alpha$ の非子孫からなる集合とした時、  
$nd(\alpha) = \bf V$$\backslash \bigl(de(\alpha) \cup \{a\} \bigr)$である
</div>

## DAGで登場する用語2 {#DAG_2}

* $an(\beta)$ を$\beta$ の先祖からなる集合とした時

<div class="box">
* 頂点集合$\bf V$ の部分集合$\bf V^*$おいて、  
$\bf V^*$ に含まれる任意の頂点 $\alpha$ に対して、  
$\alpha$ の先祖からなる集合 $an(\alpha)$ が$\bf V^*$ に含まれる時、  
$\bf V^*$ を**先祖集合**（ancestral set）という
* $\bf V$ の部分集合$\bf V^*$ に対して、$\bf V^*$ を含む最小の  
先祖集合を**最小先祖集合**（smallest ancestral set）といい、$An(\bf V^*$$)$ で表す
</div>

## DAGで登場する用語3 {#DAG_3}
<div class="box">
* 道 $\alpha_0,\alpha_1,\cdots,\alpha_n$ で $\alpha_{i-1}\circ\!\!\rightarrow\alpha_i$ かつ $\alpha_{i+1}\circ\!\!\rightarrow\alpha_i$   
つまり

$$
\alpha_{i-1}\circ\!\!\rightarrow\alpha_i\leftarrow\!\!\circ\:\alpha_{i+1}
\tag{2.54}
$$

であるとき$\alpha_i$ を**合流点**（collider）  
そうでないとき、$\alpha_i$ を**非合流点**（non-collider）という 

* $\circ\!\!\rightarrow$ は $\rightarrow$ または $\leftrightarrow$ のどちらでもよい  
* （2.54）式において、$\alpha_{i-1}$ と $\alpha_{i+1}$ の間に矢線のないグラフ構造を**V字構造**（V-structure）という
</div>

<div class="box">
* **双方向道**（bidirected path）: $\alpha_0$ と $\alpha_n$ のそれぞれへ向かう矢線を含む道
  * 双方向矢線は双方向道の1つ
</div>

# 2.7 有向分離基準

## 定義2-5 有向分離基準 (d-separation criterion) {#d_sepa}

<div class="box">
DAG $G$ において、頂点集合 $\bf X$ の任意の要素 $X$ と  
$\bf Y$ の任意の要素 $Y$ を結ぶ全ての道のそれぞれについて、  
$\bf X \cup Y$ と排反な頂点集合 $\bf Z$ が次のいずれかを満たす時  
$\bf Z$ は $\bf X$ と $\bf Y$ を**有向分離する**という  

1. $X$ と $Y$ を結ぶ道上の合流点で、  
その合流点とその子孫が $\bf Z$ に含まれないものがある  
2. $X$ と $Y$ を結ぶ道に非合流点で、  
$\bf Z$ に含まれるものがある
</div>

* 特に $X$ と $Y$ を結ぶ道が存在しない場合、  $\bf X \cup Y$ と  
排反な任意の頂点集合が $\bf X$ と $\bf Y$ を有向分離する

## 有向分離の概念

* 有向分離の概念は頂点間について定義されたもので、  
道に対して定義されたものでない
  * 因果推論の教科書ではこの区別なしに用いられることが多い
  * $\bf X$ と $\bf Y$ の有向分離関係を調べる際、任意の要素 $X$ と  
  任意の要素 $Y$ を結ぶ全ての道「それぞれ」について定義2-5の  
  条件1または条件2のどちらを満たすのかを確認

<div class="box">
* DAG $G$ において、$X$ と $Y$ を結ぶ道のうち興味のある  
ものについて、$\{X,Y\}$ と排反な頂点集合 $\bf Z$ が、  
定義2-5の条件1と条件2のいずれかを満たす時、  
$\bf Z$ はその道を**有向分離する**（ブロックする）  
* 有向分離されている$X$ と $Y$ の道のうち興味あるものについて、$\bf Z$ によってこの道が有向分離されなくなる時、$\bf Z$ はその道を**開く**
  * $\bf X$ と $\bf Y$ の間の道が有向分離されていない時、  
$\bf X$ と $\bf Y$ の間の道は**開かれている**  
</div>

## W字構造（W-structure）の例-1 {#W-structure1}

* 有向グラフにおいて、$X$ と $Y$ を結ぶ道は次の1つのみ
* 合流点である $Z_1,Z_3$ は子孫を持たない
* $Z_2$ は非合流点

$$
X \rightarrow Z_1 \leftarrow Z_2 \rightarrow Z_3 \leftarrow Y \tag{2.55}
$$

* 興味ある頂点集合 $\bf Z$ が定義2-5の条件1と条件2の  
いずれか1つを満たしていれば、  
$\bf Z$ は$X$ と $Y$ を有向分離する

## W字構造（W-structure）の例-2 {#W-structure2}

* まずは空集合を考える
  * 非合流点 $Z_2$ は空集合に含まれないため、条件2を満たさない
  * 空集合は合流点 $Z_1,Z_3$ も含んでいないため、条件1を満たす

<div class="box">
空集合は $X$ と $Y$ を有向分離する
</div>

* $Z_2$ を含む頂点集合 $\{Z_2\},\{Z_1,Z_2\},\{Z_2,Z_3\},\{Z_1,Z_2,Z_3\}$ を考える
  * 非合流点 $Z_2$ を含むため、条件2を満たす
  
<div class="box">
条件1を満たすかどうかに関係なく、  
$Z_2$ を含む頂点集合は $X$ と $Y$ を有向分離する
</div>

## W字構造（W-structure）の例-3 {#W-structure3}

* $\{Z_1\}$ を考える
  * $Z_1$ は合流点であり非合流点 $Z_2$ を含まないため、  
  条件2を満たさない
  * もう1つの合流点 $Z_3$ は $\{Z_1\}$ に含まれないため、  
  条件1を満たす
  
<div class="box">
$\{Z_1\}$ は $X$ と $Y$ を有向分離する  
同様に $\{Z_3\}$ も $X$ と $Y$ を有向分離する 
</div>

* 興味ある2つの頂点集合の間の道のそれぞれについて、  
定義2-5の片方の条件を満たすことが分かれば、  
もう1つの条件を満たすかどうかとは無関係に  
$X$ と $Y$ を有向分離すると主張可能

## W字構造（W-structure）の例-4 {#W-structure4}

* $\{Z_1,Z_3\}$ を考える
  * 非合流点 $Z_2$ を含まないため、条件2を満たさない  
  * 集合に含まれる $Z_1,Z_3$ は合流点であるため、  
  条件1を満たさない
  
<div class="box">
$\{Z_1,Z_3\}$ は $X$ と $Y$ を有向分離しない  
$\{Z_1,Z_3\}$ は (2.55) 式で与えられる道を開いている
</div>

## 有向分離基準の直感的理解のために

* グラフを1次関数に基づくデータ伝達過程と結びつけて  
考える
* 有向グラフ上の2つの頂点 $X$ と $Y$ について、

$$
Y = \alpha_{yx}X \tag{2.56}
$$

のように $Y$ の出力情報が生成される状況を示すとする

## 連鎖経路（chain）

$$
X \rightarrow Z \rightarrow Y \;\; (Y = \alpha_{yx}Z,Z = \alpha_{zx}X)
$$

は $Z$ が $X$ と $Y$ を有向分離しているケース  

* $Y$ の出力情報は $Z$ の入力情報だけで決まり、  
$X$ の入力情報とは無関係

## 分岐経路（fork）

$$
X \leftarrow Z \rightarrow Y \;\; (Y = \alpha_{yx}Z,X = \alpha_{xz}Z)
$$

は $Z$ が $X$ と $Y$ を有向分離しているケース  

* $X$ と $Y$ の出力情報は $Z$ の入力情報だけで決まる  
* $Z$ に情報が入力されると、$Y$ の出力情報は  
$X$ の出力情報とは無関係

## 合流経路（inverted fork）

$$
X \rightarrow Z \leftarrow Y \;\; (Z = \alpha_{zy}Y + \alpha_{zx}X)
$$

は空集合が$X$ と $Y$ を有向分離しているが、  
$Z$ は $X$ と $Y$ を有向分離しないケース  

* $X$ と $Y$ の2つの入力情報に基づいて $Z$ の出力情報が生成されるが、$X$ と $Y$ は無関係  
* $X$ と $Y$ の両方の情報から生成された $Z$ の出力情報が $z$ であるとき、次の関数関係を得る

$$
Y = \frac{z}{\alpha_{zy}}-\frac{\alpha_{zx}X}{\alpha_{zy}} \tag{2.57}
$$

* $Z$ の出力情報を考慮することで $X$ と $Y$ は関係を持つ

## 有向分離基準の直感的理解の難しさ1 {#difficult_1}

* $Y$ 字構造（Y-structure）を例に考える
* $X$ と $Y$ の間に $Z_1$ を通る道は存在しないため、  
$Z_1$ は $X$ と $Y$ を有向分離するように見える  
* しかし定義2-5を適用すると、$X$ と $Y$ は空集合によって  
有向分離されるが、$Z_1$ によって有向分離されなくなる  
* データ伝達過程で考えたとき、  
$Z_1$ の出力情報が$Z_1=z_1$ とわかると$Z_2$ は、

$$
Z_2 = \frac{z_1}{\alpha_{z_1z_2}} \tag{2.58}
$$

## 有向分離基準の直感的理解の難しさ2 {#difficult_2}

* ここで、

$$
Z_2 = \alpha_{z_2x}X + \alpha_{z_2y}Y \tag{2.59}
$$

であることより、

$$
\frac{z_1}{\alpha_{z_1z_2}} = \alpha_{z_2x}X + \alpha_{z_2y}Y \tag{2.60}
$$

となる  

* 合流点と同様の議論より、$Z_1$の出力情報が与えられれば  
その情報が$Z_2$に引き継がれ、その結果 $X$ と $Y$ は  
$Z_1$ によって有向分離されなくなる

# 2.8 ベイジアンネットワーク

## ベイジアンネットワークの定義

<div class="box">
双方向矢線のないDAG $G =$$\bf(\bf V,\bf E)$ が  
$\bf V =$$\{X_1,_\cdots,X_p\}$ の同時分布をグラフ$G$ に従う  
逐次的因数分解の形、つまり

$$
pr(x_1,_\cdots,x_p) = \prod^p_{i=1}pr(x_i|pa(x_i)) \tag{2.61}
$$

の形に規定する時、グラフ$G$を**ベイジアンネットワーク**（有向独立グラフ）という  
$pr(x_i|pa(x_i))$は$X_i$の親集合$pa(X_i) = pa(x_i)$を  
与えた時の$X_i$の確率分布であり、  
$pa(X_i)$が空集合の時は$X_i$の周辺分布$pr(x_i)$を表す
</div>

## 因果ダイアグラムとの比較

* ベイジアンネットワーク
  * DAGを条件付き独立関係の視覚的表現あるいは同時分布の近似的表現とみなす
* 因果ダイアグラム（詳細は第3章）
  * DAGをデータ生成過程の視覚的表現とみなす
  * 同時分布の良い近似を与えているとは限らない

## ベイジアンネットワークの構成方法1{#making_1}

* 連鎖公式(2.36) 式より、$p$次元同時分布$pr(x_1,_\cdots,x_p)$は任意の順序で逐次的因数分解でき、それぞれに対応するベイジアンネットワークを構成可能  
  * やみくもに同時分布を逐次的因数分解し、ベイジアンネット  
  ワークを構成しても統計的独立関係に関する表現能力は低く、  
  視覚的表現は理論的、実用的ともにあまり役に立つものでない
$\quad$  
* まず、$X_i$の条件付き確率分布$pr(x_i|x_1,_\cdots,x_{i-1})$が  
$X_1,_\cdots,X_{i-1} \;(i=1,_\cdots,p)$ 全てではなく、
ある変数集合$pa(X_i)$によって規定されているとする  
  * ここに$pa(x_i)$は$X_i$と$pa(X_i)$以外の変数集合  
  $\{X_1,_\cdots,X_{i-1}\}\backslash pa(X_i)$と条件付き独立とするような極小集合
  
## ベイジアンネットワークの構成方法2{#making_2}

* (2.36) 式の積より、条件付き確率分布はそれぞれ、

$$
pr(x_i|x_1,_\cdots,x_{i-1}) = pr(x_i|pa(x_i)) \; i=1,_\cdots,p \tag{2.62}
$$

* $X_1,_\cdots,X_{i-1}$を与えたときの$X_i$の確率分布ではなく、
$pa(X_i)$を与えた時の$X_i$の確率分布のみに注目  
* $pa(X_i)$をDAGにおける親集合とみなし  
その各要素から$X_i$へ矢線を引く  
$\quad$  
* ベイジアンネットワークの構成方法により  
次の2つの定理が成立  
  * 局所的有向マルコフ性（local directed Markov property）  
  * 大域的有向マルコフ性（global directed Markov property）

## 定理2-2 局所的有向マルコフ性{#local_Markov}

<div class="box">
ベイジアンネットワーク$G$において、  
任意の変数$X$に対して、その親集合$pa(X)$を与えた時、  
$X$の親以外の非子孫からなる集合$nd(X)$と$X$は  
条件付き独立  
つまり(2.63) 式の**局所的有向マルコフ性**が成り立つ  

$$
X\indep \bigl(nd(X)\backslash pa(X)\bigr)|pa(X) \tag{2.63}
$$

$pa(X)$が空集合の時は$X\indep nd(X)$
</div>

* 同時分布の条件付き独立関係が局所的有向マルコフ性  
のみで即座にわかるわけではない（M字構造の例）

## M字構造（M-structure）の例 {#M-structure}

* 図2-4のM字構造をもつ有向グラフをベイジアン  
ネットワークとみなすと、対応する同時分布の  
逐次的因数分解は

$$
pr(x,y,z_1,z_2,z_3) = pr(y|z_3)pr(z_2|z_1,z_3)pr(x|z_1)pr(z_1)pr(z_3) \tag{2.64}
$$

* このとき、局所的有向マルコフ性により

$$
X\indep \{Z_2,Z_3,Y\}|Z_1,\; Y\indep  \{Z_1,Z_2,X\}|Z_3\\
Z_2\indep \{X,,Y\}|\{Z_1,Z_3\},\; Z_1\indep Z_3 \tag{2.65}
$$

* しかし、

$$
X \indep Y \tag{2.66}
$$

が成立することを直接確かめられず、グラフォイド原理を  
繰り返し適用することで（2.66）式を導く

## 定理2-3 大域的有向マルコフ性{#global_Markov}

<div class="box">
ベイジアンネットワーク$G$において、$\bf Z$が$\bf X$と$\bf Y$を  
有向分離するなら、頂点に対応する確率変数において、    
$\bf Z$を与えた時、$\bf X$と$\bf Y$は条件付き独立  
つまり(2.67) 式の**大域的有向マルコフ性**が成り立つ  

$$
\bf X \indep Y|Z \tag{2.67}
$$

</div>

* ベイジアンネットワーク$G$において$\bf Z$が$\bf X$と$\bf Y$を   
有向分離しない時、$\bf X \notindep Y|Z$が成り立つことを  
述べているわけではない
  * 一般に$\bf X \notindep Y|Z$が成り立つかどうかをグラフ構造からは  
  判断できない
  
## Y字構造のベイジアンネットワーク1{#Y-structure1}

* 同時分布の逐次的因数分解は

$$
pr(x,y,z_1,z_2) = pr(z_1|z_2)pr(z_2|x,y)pr(x)pr(y) \tag{2.68}
$$

* この式より

$$
Z_1 \indep \{X,Y\}|Z_2,\; X \indep Y \tag{2.69}
$$

* 図を見れば上記の逐次的因数分解を行わなくても
  * $Z_2$は$Z_1$と$\{X,Y\}$を有向分離
  * 空集合が$X$と$Y$を有向分離
* 定理2-3より
  * $Z_2$を与えた時、$Z_1$と$\{X,Y\}$は条件付き独立
  * 空集合$\phi$を与えた時、$X$と$Y$は条件付き独立
  
## Y字構造のベイジアンネットワーク2{#Y-structure2}

* 連鎖公式(2.36)式は任意の変数順序に対して  
適用可能であることを利用  
* (2.68)式の左辺をあえて以下のように逐次的因数分解

$$
pr(x,y,z_1,z_2) = pr(x|y,z_1,z_2)pr(y|z_1,z_2)pr(z_2|z_1)pr(z_1) \tag{2.70}
$$

* (2.69)式より定理2-1の弱結合性を用いて

$$
Z_1\indep X|\{Y,Z_2\} \tag{2.71}
$$

* 定理2-1の分解性を用いて

$$
Z_1\indep Y|Z_2 \tag{2.72}
$$

* これらより、 (2.70)式は以下のように書き直せる

$$
pr(x,y,z_1,z_2) = pr(x|y,z_2)pr(y|z_2)pr(z_2|z_1)pr(z_1) \tag{2.73}
$$

## Y字構造のベイジアンネットワーク3{#Y-structure3}

* (2.73)式よりベイジアンネットワークとみなせる
* $Z_2$が$Z_1$と$\{X,Y\}$を有向分離しているため

$$
Z_1 \indep \{X,Y\}|Z_2 \tag{2.74}
$$

は成り立つが、(2.75)式をグラフから読み取れない

$$
X \indep Y \tag{2.75}
$$

* ベイジアンネットワークから導かれる有向分離関係のみ  
では確率分布によって規定される条件付き独立関係を  
十分に記述できないケースが存在  
➡「︎ベイジアンネットワークを用いて因果関係を  
記述する際に引き起こされる問題」


## 例：表2-1の例1 {#ex_2_1_1}

* グラフを用いて条件付き独立関係を過度に  
記述することでデータ生成過程とは異なった  
変数順序をもつ有向グラフが得られる例  

* 確率的関係を視覚化：図2-6(a)の有向グラフになる
* 一方、表2-1において(2.77)式が成り立つ

$$
Y \indep Z \tag{2.77}
$$

* 有向分離性を踏まえて、表2-1の条件付き独立関係(2.77)式を反映させたベイジアンネットワークを構成：図2-6(b)

## 例：表2-1の例2 {#ex_2_1_2}

* 図2-6(a)では$Z$から$Y$へ向かう矢線$(Z \rightarrow Y)$が存在
* 図2-6(b)では$Y$と$Z$は矢線や双方向矢線で結ばれていない
  * 表2-1から導かれる統計的独立関係を出来る限り視覚的に表現

# 2.9 ランダム化












