---
title: "離散型分布"
author: "谷口友哉"
date: "`r Sys.Date()`"
output:
  rmdformats::downcute:
    code_folding: hide
    self_contained: TRUE
    thumbnails: FALSE
    lightbox: FALSE
    css: style.css
    md_extensions: -ascii_identifiers
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}

---

# キーワード

* 離散一様分布
* ベルヌーイ分布
* 二項分布
* 超幾何分布
* ポアソン分布
* 幾何分布
* 負の二項分布
* 多項分布

# 離散一様分布

## 定義{#discrete_uniform_distribution1}

確率変数 $X$ が $1,2,\dots,K$ を等確率で取る、つまり

$$
P(X = 1) = P(X = 2) = \cdots = P(X = K) = \frac{1}{K}
$$

であるとき、$X$ の分布を $\left\{1,2,\dots,K\right\}$ 上の **離散一様分布** (discrete uniform distribution) という

## 期待値と分散･確率母関数{#discrete_uniform_distribution2}

期待値と分散は以下の通り

$$
E[X] = \frac{K + 1}{2},\:\: V[X] = \frac{K^2-1}{12}
$$
(証明)

確率母関数は以下の通り

$$
G(s) = E\left[s^X\right] = \frac{s + s^2 + \cdots + s^K}{K} = \frac{s\left(1 - s^K\right)}{K\left(1 - s\right)}
$$

# ベルヌーイ分布

## ベルヌーイ試行

2つの結果のうち、いずれか一方が起こる試行を考える  
一方を「成功」、もう一方を「失敗」と呼ぶ  
成功の起こる確率を成功確率 $p (0<p<1)$ とする試行を **ベルヌーイ試行** (Bernoulli trial) という

## 定義{#Bernoulli_distribution1}

成功確率 $p$のベルヌーイ試行に対し、確率変数 $X$ を成功の時 $1$、失敗の時 $0$ をとると定義  
($X$ はベルヌーイ試行を1回行った時の成功の回数)  
$X$ の従う分布を、成功確率 $p$ の **ベルヌーイ分布** (Bernoulli distribution) といい、$Bin(1,p)$ と表す

$Bin(1,p)$ の確率変数は、$q := 1 - p$ を用いて以下のように書ける

$$
P(X = x) = p^xq^{1-x} , \;x = 0,1
$$

## 期待値と分散･確率母関数{#Bernoulli_distribution2}

$Bin(1,p)$ の期待値と分散は以下の通り

$$
E[X] = p,\:\: V[X] = pq \tag{5.1}
$$

(証明)
$$
E[X] = 1 \times p + 0 \times q = p
$$

また、$X = 0,1$ より、$X^2 = X$ なので、$E[X^2] = E[X] = p$ であるので、

$$
V[X] = E\left[X^2\right] - \left(E[X]\right)^2 = p - p^2 = p(1 - p) = pq
$$

確率母関数は以下の通り

$$
G(s) = E\left[s^X\right] = s^1 \times p + s^0 \times q =ps + q \tag{5.2}
$$


# 二項分布

## 定義{#binomial_distribution1}

成功確率 $p \;(0<p<1)$のベルヌーイ試行を $n$ 回行い、$i\;(1\leq i \leq n)$ 回目のベルヌーイ試行に対応する確率変数を $X_i$ とする  
(和$X_1 + \cdots + X_n$ は $n$ 回中の成功回数)  
ここで、$X_1, \dots , X_n$ が独立であるとき、$Y = X_1 + \cdots + X_n$ が従う分布を、<br>
成功確率 $p$ の **二項分布** (binomial distribution) といい、$Bin(n,p)$ と表す  
(独立なベルヌーイ試行を $n$ 回行った時の成功回数 $Y$ の分布が二項分布)

$Bin(1,p)$ の確率変数は、$q := 1 - p$ を用いて以下のように書ける

$$
P(Y = y) = {}_n C_y p^yq^{1 - y}, \;y = 0,1,\dots,n  \tag{5.3}
$$
これは与えられた $y \:(0\leq y \leq n)$ に対し、 $n$ 回の独立なベルヌーイ試行のうち成功 $y$ 回、<br>
失敗 $n - y$ 回となるような列を考えると、列の総数は $n$ 回の試行のうち成功が起こった $y$ 回を選ぶ方法に<br>
特定の列が生じる確率を掛け合わせたものと同義である

## 期待値と分散･確率母関数{#binomial_distribution2}

$Bin(n,p)$ の期待値と分散、確率母関数は以下の通り

$$
E[Y] = np,\:\: V[Y] = npq,\:\: G(s) = E\left[s^Y\right] = \left(ps + q\right)^n  \tag{5.4}
$$

(証明) 

$Bin(1,p)$ の期待値と分散･確率母関数より導出できる

$Y \sim Bin(n,p)$ の時、$Y = X_1 + \cdots + X_n, \:X_1, \dots, X_n \overset{iid}{\sim} Bin(1,p)$ と考えて良いので、式(5.1)、(5.2) より

$$
E[Y] = E[X_1] + \cdots + E[X_n] = nE[X_1] = np
$$


$$
V[Y] = V[X_1] + \cdots + V[X_n] = nV[X_1] = npq
$$

$$
G(s) = E\left[s^Y\right] = E\left[s^{X_1}\right] \times \cdots E\left[s^{X_n}\right]= \left(E\left[s^{X_1}\right]\right)^2 = \left(ps + q\right)^n 
$$

## 二項分布の再生性{#binomial_distribution3}

$Y_1 \sim Bin(n_1,p)$ と $Y_2 \sim Bin(n_2,p)$ が独立ならば、$Y_1 + Y_2 \sim Bin(n_1 + n_2,p)$ となる

(証明) 

式(5.4) より、$Y_1 + Y_2 $ の確率母関数が以下のようになり、<br>
$Bin(n_1 + n_2,p)$ の確率母関数に一致することからわかる

$$
E\left[s^{Y_1 + Y_2}\right] = E\left[s^{Y_1}s^{Y_2}\right] = E\left[s^{Y_1}\right] E\left[s^{Y_2}\right] = \left(ps + q\right)^{n_1}\left(ps + q\right)^{n_2} = \left(ps + q\right)^{n_1 + n_2}  
$$

# 超幾何分布

## 定義{#hypergeometric_distribution1}

壺の中に $N$ 個の玉が入っており、そのうち $M$ 個は赤玉、残りの $N - M$ 個は白玉である $(0 < M < N)$

よく混ぜ、壺から $n$ 個 取り出すとき、 $n$ 個中 $Y$ 個が赤玉だったとする  
($n = 1$ ならば、 $Y \sim Bin\left(1,\frac{M}{N}\right)$ )

復元無作為抽出 (1つ取り出すごとにその玉を壺に戻し、次の玉を取り出す) のときは、<br>
赤玉の割合 $\frac{M}{N}$ は変化しないため、取り出された赤玉の個数 $Y$ は二項分布 $Bin\left(n,\frac{M}{N}\right)$ に従う

一方で、非復元無作為抽出 (取り出した玉を壺に戻さず、次の玉を取り出す) のときは<br>
それまでに取り出された赤玉と白玉の数によって壺の中の赤玉の割合は変化し、$Y$ は二項分布に従わない

非復元無作為抽出のとき、$Y$ は **超幾何分布** (hypergeometric distribution) に従い、$HG(N,M,n)$ と表す  
($M$ 個の赤玉と $N - M$ 個の白玉の合計 $N$ 個の玉が入った壺から、<br>
非復元無作為抽出で $n$ 個の玉を取り出す時、取り出された $n$ 個のうちの赤玉の個数 $Y$ が<br>
超幾何分布 $HG(N,M,n)$ に従う)

$Y \sim HG(N,M,n)$ の確率変数は以下のように書ける

$$
P(Y = y) = \frac{{}_M C_y \times {}_{N-M} C_{n -y}}{{}_N C_n}, \; \max\{0,n - (N - M)\} \leq y \leq \min\{n,M\}  \tag{5.5}
$$

ここで、$\max\{0,n - (N - M)\} \leq y \leq \min\{n,M\}$ は $0 \leq y \leq M,\:0 \leq n - y \leq N -M$ の言いかえである  
($a < 0$ または $b < 0$ のとき、${}_a C_b = 0$ と考えるならばこの条件は不要)

なお、$n$ と $\frac{M}{N} := p$ を一定のまま、$N \rightarrow \infty \: (M = Np \rightarrow \infty)$ とすると、<br>
式(5.5)は二項分布 $Bin(n,p)$ の確率関数に各 $y$ で収束し、復元抽出と非復元抽出の差がなくなる

## 期待値と分散{#hypergeometric_distribution2}

$HG(N,M,n)$ の期待値と分散は以下の通り

$$
E[Y] = n \cdot  \frac{M}{N},\:\: V[Y] = n \cdot  \frac{M}{N} \left(1 - \frac{M}{N}\right) \times \frac{N - n}{N - 1} \tag{5.6}
$$


期待値は、復元抽出の場合の二項分布 $Bin\left(n,\frac{M}{N}\right)$ の期待値と一致  
分散は、復元抽出の場合の二項分布 $Bin\left(n,\frac{M}{N}\right)$ の分散を $\frac{\left(N - n \right)}{\left(N - 1 \right)}$ 倍したもの  
$n \geq 2$ のとき $\frac{\left(N - n \right)}{\left(N - 1 \right)} < 1$ であり、$\frac{\left(N - n \right)}{\left(N - 1 \right)} < 1$ を **有限母集団修正** (finite population correction) という

超幾何分布の確率母関数は超幾何関数を用いて表す (具体的な形は省略)

# ポアソン分布

## 定義{#Poisson_distribution1}

非負整数値をとる確率変数 $Y$ が、ある $\lambda > 0$ に対して以下の確率関数をもつとする

$$
P(Y = y) = \frac{\lambda^y}{y!}e^{-\lambda},\:\:y = 0,1,2,\dots \tag{5.7}
$$

このとき $Y$ は **ポアソン分布** (Poisson distribution) に従い、$Po(\lambda)$ と表す  
式 (5.7) が確率変数になることは、次のようにわかる

$$
\sum^{\infty}_{y = 0}\frac{\lambda^y e^{-\lambda}}{y!} = e^{-\lambda}\sum^{\infty}_{y = 0}\frac{\lambda^y}{y!} = e^{-\lambda}e^{\lambda} = 1
$$

$Po(\lambda)$ の確率関数 (5.7) は、二項分布 $Bin(n.p)$ の確率関数 (5.3)　において、<br>
$np$ を $\lambda \;(> 0)$ に固定して $n \rightarrow \infty \; (n \rightarrow \infty, p = \frac{\lambda}{n} \rightarrow 0)$ とした場合の極限として得られる

$$
{}_n C_y \left(\frac{\lambda}{n}\right)^y \left(1-\frac{\lambda}{n}\right)^{n -y} \rightarrow \frac{\lambda^y}{y!}e^{-\lambda} \;\;(n \rightarrow \infty) \tag{5.8}
$$

## 確率母関数･期待値と分散{#Poisson_distribution2}

$Po(\lambda)$ の確率母関数は以下の通り

$$
G(s) = E\left[s^Y\right] = e^{\lambda(s - 1)} \tag{5.9}
$$

(証明)

$$
E\left[s^Y\right] = \sum^{\infty}_{y = 0} s^y \cdot \frac{\lambda^y e^{-\lambda}}{y!} = e^{-\lambda} \sum^{\infty}_{y = 0} \frac{(\lambda s)^y}{y!} = e^{-\lambda}e^{\lambda s} = e^{\lambda(s - 1)}
$$

$Po(\lambda)$ の期待値と分散は以下の通り

$$
E[Y] = \lambda,\:\: V[Y] = \lambda \tag{5.10}
$$

(証明)

$$
G'(s) = \lambda e^{\lambda(s - 1)},\:\: G''(s) = \lambda^2 e^{\lambda(s - 1)}\\
E[Y] = G'(1) =  \lambda ,\:\: V[Y] = E[Y(Y - 1)] + E[Y] -\left(E[Y]\right)^2 = G''(1) + \lambda - \lambda^2 = \lambda^2 + \lambda -\lambda^2 = \lambda
$$

式 (5.10) は、式 (5.8) で極限をとる前の二項分布 $Bin(n,p)$ の期待値 $np = \lambda$ と<br>
分散 $np(1 - p) = \lambda\left(1 - \left(\frac{\lambda}{n}\right)\right)$ の極限を考えても予想できる

# 幾何分布



# 負の二項分布



# 多項分布





