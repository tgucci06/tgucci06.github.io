---
title: "離散型分布 まとめ"
author: "谷口友哉"
date: "`r Sys.Date()`"
output:
  rmdformats::downcute:
    code_folding: hide
    self_contained: TRUE
    thumbnails: FALSE
    lightbox: FALSE
    css: style.css
    md_extensions: -ascii_identifiers
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r,message = FALSE}
library(tidyverse)
```

# キーワード

* 離散一様分布
* ベルヌーイ分布
* 二項分布
* 超幾何分布
* ポアソン分布
* 幾何分布
* 負の二項分布
* 多項分布

# 離散一様分布

## 定義

確率変数 $X$ が $1,2,\dots,K$ を等確率で取る、つまり

$$
P(X = 1) = P(X = 2) = \cdots = P(X = K) = \frac{1}{K}
$$

であるとき、$X$ の分布を $\left\{1,2,\dots,K\right\}$ 上の **離散一様分布** (discrete uniform distribution) という

(例) 均等なサイコロを10,000回投げる

```{r}
a1 <- sample(1:6, size = 10000, replace = TRUE)
df1 <- tibble(a1)
ggplot(df1, aes(x = a1)) +
  geom_bar(width = 0.5) +
  labs(x = "出た目", y = "回数") +
  scale_x_continuous(breaks = 1:6) +
   theme_gray (base_family = "HiraKakuPro-W3")
```


## 期待値と分散･確率母関数

期待値と分散は以下の通り

$$
E[X] = \frac{K + 1}{2},\:\: V[X] = \frac{K^2-1}{12}
$$
(証明)

以下の有名な公式より容易に導ける

$$
1 + 2 + \cdots + K = \frac{K(K + 1)}{2}\\
1^2 + 2^2 + \cdots + K^2 = \frac{K(K + 1)(2K + 1)}{6}
$$

確率母関数は以下の通り

$$
G(s) = E\left[s^X\right] = \frac{s + s^2 + \cdots + s^K}{K} = \frac{s\left(1 - s^K\right)}{K\left(1 - s\right)}
$$

# ベルヌーイ分布

## ベルヌーイ試行

2つの結果のうち、いずれか一方が起こる試行を考える  
一方を「成功」、もう一方を「失敗」と呼ぶ  
成功の起こる確率を成功確率 $p (0<p<1)$ とする試行を **ベルヌーイ試行** (Bernoulli trial) という

## 定義

成功確率 $p$のベルヌーイ試行に対し、確率変数 $X$ を成功の時 $1$、失敗の時 $0$ をとると定義  
($X$ はベルヌーイ試行を1回行った時の成功の回数)  
$X$ の従う分布を、成功確率 $p$ の **ベルヌーイ分布** (Bernoulli distribution) といい、$Bin(1,p)$ と表す

$Bin(1,p)$ の確率変数は、$q := 1 - p$ を用いて以下のように書ける

$$
P(X = x) = p^xq^{1-x} , \;x = 0,1
$$

## 期待値と分散･確率母関数

$Bin(1,p)$ の期待値と分散は以下の通り

$$
E[X] = p,\:\: V[X] = pq \tag{5.1}
$$

(証明)
$$
E[X] = 1 \times p + 0 \times q = p
$$

また、$X = 0,1$ より、$X^2 = X$ なので、$E[X^2] = E[X] = p$ であるので、

$$
V[X] = E\left[X^2\right] - \left(E[X]\right)^2 = p - p^2 = p(1 - p) = pq
$$

確率母関数は以下の通り

$$
G(s) = E\left[s^X\right] = s^1 \times p + s^0 \times q =ps + q \tag{5.2}
$$


# 二項分布

## 定義

成功確率 $p \;(0<p<1)$ のベルヌーイ試行を $n$ 回行い、<br>
$i\;(1\leq i \leq n)$ 回目のベルヌーイ試行に対応する確率変数を $X_i$ とする  
(和$X_1 + \cdots + X_n$ は $n$ 回中の成功回数)  
ここで、$X_1, \dots , X_n$ が独立であるとき、$Y = X_1 + \cdots + X_n$ が従う分布を、<br>
成功確率 $p$ の **二項分布** (binomial distribution) といい、$Bin(n,p)$ と表す  
(独立なベルヌーイ試行を $n$ 回行った時の成功回数 $Y$ の分布が二項分布)

$Bin(1,p)$ の確率変数は、$q := 1 - p$ を用いて以下のように書ける

$$
P(Y = y) = {}_n C_y p^yq^{1 - y}, \;y = 0,1,\dots,n  \tag{5.3}
$$

これは与えられた $y \:(0\leq y \leq n)$ に対し、 $n$ 回の独立なベルヌーイ試行のうち成功 $y$ 回、<br>
失敗 $n - y$ 回となるような列を考えると、列の総数は $n$ 回の試行のうち成功が起こった $y$ 回を選ぶ方法に<br>
特定の列が生じる確率を掛け合わせたものと同義である

(例) 表が少し出やすいコイン (0.6の確率で表が出る) を1回の実験で10回投げ、表が出た回数を記録。  
この実験を300回繰り返す

```{r}
a2 <- rbinom(n = 300, size = 10, prob = 0.6)
df2 <- tibble(a2)
ggplot(df2, aes(x = a2)) +
  geom_bar(width = 0.5) +
  labs(x = "成功回数", y = "確率") +
  scale_x_continuous(breaks = 0:10) +
  theme_gray (base_family = "HiraKakuPro-W3")
```


## 期待値と分散･確率母関数

$Bin(n,p)$ の期待値と分散、確率母関数は以下の通り

$$
E[Y] = np,\:\: V[Y] = npq,\:\: G(s) = E\left[s^Y\right] = \left(ps + q\right)^n  \tag{5.4}
$$

(証明) 

$Bin(1,p)$ の期待値と分散･確率母関数より導出できる

$Y \sim Bin(n,p)$ の時、$Y = X_1 + \cdots + X_n, \:X_1, \dots, X_n \overset{iid}{\sim} Bin(1,p)$ と考えて良いので、式(5.1)、(5.2) より

$$
E[Y] = E[X_1] + \cdots + E[X_n] = nE[X_1] = np
$$


$$
V[Y] = V[X_1] + \cdots + V[X_n] = nV[X_1] = npq
$$

$$
G(s) = E\left[s^Y\right] = E\left[s^{X_1}\right] \times \cdots E\left[s^{X_n}\right]= \left(E\left[s^{X_1}\right]\right)^2 = \left(ps + q\right)^n 
$$

## 二項分布の再生性

$Y_1 \sim Bin(n_1,p)$ と $Y_2 \sim Bin(n_2,p)$ が独立ならば、$Y_1 + Y_2 \sim Bin(n_1 + n_2,p)$ となる

(証明) 

式(5.4) より、$Y_1 + Y_2 $ の確率母関数が以下のようになり、<br>
$Bin(n_1 + n_2,p)$ の確率母関数に一致することからわかる

$$
E\left[s^{Y_1 + Y_2}\right] = E\left[s^{Y_1}s^{Y_2}\right] = E\left[s^{Y_1}\right] E\left[s^{Y_2}\right] = \left(ps + q\right)^{n_1}\left(ps + q\right)^{n_2} = \left(ps + q\right)^{n_1 + n_2}  
$$

# 超幾何分布

## 定義

壺の中に $N$ 個の玉が入っており、そのうち $M$ 個は赤玉、<br>
残りの $N - M$ 個は白玉である $(0 < M < N)$ とする  

よく混ぜ、壺から $n$ 個 取り出すとき、 $n$ 個中 $Y$ 個が赤玉だったとする  
($n = 1$ ならば、 $Y \sim Bin\left(1,\frac{M}{N}\right)$ )  

復元無作為抽出 (1つ取り出すごとにその玉を壺に戻し、次の玉を取り出す) のときは、<br>
赤玉の割合 $\frac{M}{N}$ は変化しないため、取り出された赤玉の個数 $Y$ は二項分布 $Bin\left(n,\frac{M}{N}\right)$ に従う

一方で、非復元無作為抽出 (取り出した玉を壺に戻さず、次の玉を取り出す) のときは<br>
それまでに取り出された赤玉と白玉の数によって壺の中の赤玉の割合は変化し、$Y$ は二項分布に従わない

非復元無作為抽出のとき、$Y$ は **超幾何分布** (hypergeometric distribution) に従い、$HG(N,M,n)$ と表す  
($M$ 個の赤玉と $N - M$ 個の白玉の合計 $N$ 個の玉が入った壺から、<br>
非復元無作為抽出で $n$ 個の玉を取り出す時、取り出された $n$ 個のうちの赤玉の個数 $Y$ が<br>
超幾何分布 $HG(N,M,n)$ に従う)

$Y \sim HG(N,M,n)$ の確率変数は以下のように書ける

$$
P(Y = y) = \frac{{}_M C_y \times {}_{N-M} C_{n -y}}{{}_N C_n}, \; \max\{0,n - (N - M)\} \leq y \leq \min\{n,M\}  \tag{5.5}
$$

ここで、$\max\{0,n - (N - M)\} \leq y \leq \min\{n,M\}$ は $0 \leq y \leq M,\:0 \leq n - y \leq N -M$ の言いかえである  
($a < 0$ または $b < 0$ のとき、${}_a C_b = 0$ と考えるならばこの条件は不要)

なお、$n$ と $\frac{M}{N} := p$ を一定のまま、$N \rightarrow \infty \: (M = Np \rightarrow \infty)$ とすると、<br>
式(5.5)は二項分布 $Bin(n,p)$ の確率関数に各 $y$ で収束し、復元抽出と非復元抽出の差がなくなる

```{r}
ggplot(data.frame(x = c(0:10)), aes(x)) +
    geom_point(aes(y = dhyper(x, 30,70,max(x))))
```

## 期待値と分散

$HG(N,M,n)$ の期待値と分散は以下の通り

$$
E[Y] = n \cdot  \frac{M}{N},\:\: V[Y] = n \cdot  \frac{M}{N} \left(1 - \frac{M}{N}\right) \times \frac{N - n}{N - 1} \tag{5.6}
$$


期待値は、復元抽出の場合の二項分布 $Bin\left(n,\frac{M}{N}\right)$ の期待値と一致  
分散は、復元抽出の場合の二項分布 $Bin\left(n,\frac{M}{N}\right)$ の分散を $\frac{\left(N - n \right)}{\left(N - 1 \right)}$ 倍したもの  
$n \geq 2$ のとき $\frac{\left(N - n \right)}{\left(N - 1 \right)} < 1$ であり、$\frac{\left(N - n \right)}{\left(N - 1 \right)} < 1$ を **有限母集団修正** (finite population correction) という

超幾何分布の確率母関数は超幾何関数を用いて表す (具体的な形は省略)

# ポアソン分布

## 定義

非負整数値をとる確率変数 $Y$ が、ある $\lambda > 0$ に対して以下の確率関数をもつとする

$$
P(Y = y) = \frac{\lambda^y}{y!}e^{-\lambda},\:\:y = 0,1,2,\dots \tag{5.7}
$$

このとき $Y$ は **ポアソン分布** (Poisson distribution) に従い、$Po(\lambda)$ と表す  
式 (5.7) が確率変数になることは、次のようにわかる

$$
\sum^{\infty}_{y = 0}\frac{\lambda^y e^{-\lambda}}{y!} = e^{-\lambda}\sum^{\infty}_{y = 0}\frac{\lambda^y}{y!} = e^{-\lambda}e^{\lambda} = 1
$$

$Po(\lambda)$ の確率関数 (5.7) は、二項分布 $Bin(n.p)$ の確率関数 (5.3)　において、<br>
$np$ を $\lambda \;(> 0)$ に固定して $n \rightarrow \infty \; (n \rightarrow \infty, p = \frac{\lambda}{n} \rightarrow 0)$ とした場合の極限として得られる

$$
{}_n C_y \left(\frac{\lambda}{n}\right)^y \left(1-\frac{\lambda}{n}\right)^{n -y} \rightarrow \frac{\lambda^y}{y!}e^{-\lambda} \;\;(n \rightarrow \infty) \tag{5.8}
$$

```{r}
ggplot(data.frame(x = c(0:10)), aes(x)) +
    geom_point(aes(y = dpois(x, lambda = 1)))
```


## 確率母関数･期待値と分散

$Po(\lambda)$ の確率母関数は以下の通り

$$
G(s) = E\left[s^Y\right] = e^{\lambda(s - 1)} \tag{5.9}
$$

(証明)

$$
E\left[s^Y\right] = \sum^{\infty}_{y = 0} s^y \cdot \frac{\lambda^y e^{-\lambda}}{y!} = e^{-\lambda} \sum^{\infty}_{y = 0} \frac{(\lambda s)^y}{y!} = e^{-\lambda}e^{\lambda s} = e^{\lambda(s - 1)}
$$

$Po(\lambda)$ の期待値と分散は以下の通り

$$
E[Y] = \lambda,\:\: V[Y] = \lambda \tag{5.10}
$$

(証明)

$$
G'(s) = \lambda e^{\lambda(s - 1)},\:\: G''(s) = \lambda^2 e^{\lambda(s - 1)}\\
E[Y] = G'(1) =  \lambda \\ 
V[Y] = E[Y(Y - 1)] + E[Y] -\left(E[Y]\right)^2 = G''(1) + \lambda - \lambda^2 = \lambda^2 + \lambda -\lambda^2 = \lambda
$$

式 (5.10) は、式 (5.8) で極限をとる前の二項分布 $Bin(n,p)$ の期待値 $np = \lambda$ と<br>
分散 $np(1 - p) = \lambda\left(1 - \left(\frac{\lambda}{n}\right)\right)$ の極限を考えても予想できる

## ポアソン分布の再生性

$Y_1 \sim Po(\lambda_1)$ と $Y_2 \sim Po(\lambda_2)$ が独立ならば、$Y_1 + Y_2 \sim Po(\lambda_1 + \lambda_2)$ となる

(証明) 

式(5.9) の確率母関数から、二項分布の再生性と同じ議論でわかる

# 幾何分布

## 定義

成功確率 $p \;(0 < p < 1)$ の独立なベルヌーイ試行を繰り返したとき、初めて成功するまでに起こる **失敗の回数** を $X$ とする  
このとき $X$ は **幾何分布** (geometric distribution) に従い、$Geo(p)$ と表す

確率関数は $q = 1 - p$ を用いて、以下のように幾何数列 (等比数列) の形で表される

$$
P(X = x) = pq^x,\:\: x = 0,1,2,\dots
$$

これは $X = x$ となるのは「最初の $x$ 回全て失敗し、その次に成功する」ときであることを表す

```{r}
ggplot(data.frame(x = c(0:10)), aes(x)) +
    geom_point(aes(y = dgeom(x, prob = 0.4)))
```


## 確率母関数･期待値と分散

$Geo(p)$ の確率母関数は以下の通り

$$
G(s) = E\left[s^X\right] = \frac{p}{1 - qs},\:\:|s| < \frac{1}{q} \tag{5.11}
$$

(証明)

$$
E\left[s^X\right] = \sum^{\infty}_{x = 0} s^x pq^x = p \sum^{\infty}_{x = 0} \left(sq\right)^x = \frac{p}{(1 - qs)},\:\:|s| < \frac{1}{q}
$$

$Geo(p)$ の期待値と分散は以下の通り

$$
E[X] = \frac{q}{p},\:\: V[X] = \frac{q}{p^2} \tag{5.12}
$$

(証明)

$$
G'(s) = pq(1 - qs)^{-2},\:\: G''(s) = 2pq^2(1 - qs)^{-3}\\
E[X] = G'(1) =  \frac{q}{p} \\ 
V[X] = E[X(X - 1)] + E[X] -\left(E[X]\right)^2 = \frac{2q^2}{p^2} + \frac{q}{p} - \left(\frac{q}{p}\right)^2 = \frac{q}{p^2}
$$

式 (5.12) の期待値より、「失敗回数の期待値 $E[X]$」と「成功回数 $(= 1)$」の比が、<br>
「失敗確率 $q$」と「成功確率 $p$ の比に等しいことがわかる

## 幾何分布の無記憶性

$X \sim Geo(p)$ のとき、以下が成り立つことを幾何分布の **無記憶性** (memoryless property) という

$$
P\left(X \geq t_1 + t_2 \;|\;X \geq t_1\right) = P(X \geq t_2) ,\:\:t_1,t_2 = 0,1,2,\dots
$$

(証明)

$t = 0,1,2,\dots$ に対し、「$X \geq t$」が「はじめの $t$ 回が全て失敗」と同値なので $P(X \geq t) = q^t$ となるため

$$
P\left(X \geq t_1 + t_2 \;|\;X \geq t_1\right) = \frac{q^{t_1 + t_2}}{{q^{t_1}}} = q^{t_2} = P(X \geq t_2),\:\:t_1,t_2 = 0,1,2,\dots
$$ 

## 補足

「初めて成功するまでの試行回数 $W$」が従う分布を幾何分布と呼ぶこともある  
このとき、$W = X + 1$ の分布を考えればよい  
確率関数、期待値、分散、確率母関数は以下の通り

$$
P(W = w) = P(X = w - 1) = pq^{w -1},\:\: w = 1,2,\dots\\
E[W] = E[X] + 1 = \frac{q}{p} + 1 = \frac{1}{p}\\
V[W] = V[X] = \frac{q}{p^2}\\
G(s) = E\left[s^W\right] = sE\left[s^X\right] = \frac{ps}{1 - qs},\:\:|s| < \frac{1}{q}
$$

# 負の二項分布

## 定義

成功確率 $p \;(0 < p < 1)$ の独立なベルヌーイ試行を繰り返したとき、$r \in \mathbb N$ 回目の成功が起こった時点で、<br>
それまでに起こった **失敗の回数** を $Y$ とする  
このとき $Y$ は **負の二項分布** (negative binomial distribution) に従い、$NB(r,p)$ と表す  
特に $NB(1,p)$ は幾何分布 $Geo(p)$ である 

```{r}
ggplot(data.frame(x = c(0:10)), aes(x)) +
    geom_point(aes(y = dnbinom(0:10, 4, 0.3)))
```


確率関数は $q = 1 - p$ と重複組合せ ($r$ 個の異なるものから重複を許して $y$ 個を選んでできる組合せ) の<br>
総数 ${}_r \mathrm H_y$ を用いて、以下のように表される

$$
P(Y = y) = {}_r \mathrm H_y p^rq^y,\:\: y = 0,1,2,\dots \tag{5.13}
$$

これは $Y = y$ となるのは「最初の $y + r -1$ 回の試行で成功 $r -1$ 回、失敗 $y$ 回であり、<br>
$y + r$ 回の試行で成功する」ときであることを表すので、

$$
P(Y = y) = {}_r \mathrm H_y p^{r -1} q^y \times p = {}_r \mathrm H_y p^rq^y
$$


(補足) 重複組合せは具体的には以下のように書ける

$$
{}_r \mathrm H_y = {}_{y + r -1} C_y = \frac{(y + r -1)(y + r -2) \cdots (r + 1)r}{y!}
$$

## 幾何分布との関連

$X_1,\dots,X_r$ が互いに独立に幾何分布 $Geo(p)$ に従うとき、$X_1 + \dots + X_r$ が $NB(r,p)$ に従う


(証明)

確率母関数を用いて確認する

まず、$X_1 + \dots + X_r \:\:\left(X_1,\dots,X_r \overset{iid}{\sim} Geo(p)\right)$ の確率母関数は、式 (5.11) を用いると、<br>
二項分布のときと同じ議論により、

$$
E\left[s^{X_1 + \dots + X_r}\right] = \left(E\left[s^{X_1}\right]\right)^r = \left(\frac{p}{(1 - qs)}\right)^r,\:\:|s| < \frac{1}{q}
$$

他方、 $Y \sim NB(r,p)$ の確率母関数は以下のように書ける

$$
G(s) = E\left[s^{Y}\right] = \sum^{\infty}_{y = 0} s^y(-1)^y \binom{-r}{y} p^r q^y = p^r \sum^{\infty}_{y = 0} \binom{-r}{y} (-qs)^y = p^r (1 -qs)^{-r} = \left(\frac{p}{1 - qs}\right)^r ,\:\:|s| < \frac{1}{q}
$$

ここで、最後から2つ目の等号ではテイラー展開 $(1 + x)^a = \sum^{\infty}_{b = 0} \frac{(a(a-1)) \cdots (a - b + 1)}{b!}x^b = \sum^{\infty}_{b = 0}\binom{a}{b}x^b,\:\:|x| < 1$ ($\forall a \in \mathbb R$) を用いた


確率母関数が一致したので、$X_1 + \dots + X_r$ と $Y$ が従分布が一致することが確認できた

## 期待値と分散

$NB(r,p)$ の期待値と分散は以下の通り

$$
E[X] = \frac{rq}{p},\:\: V[X] = \frac{rq}{p^2} 
$$

(証明)

$X_1,\dots,X_r \overset{iid}{\sim} Geo(p)$ に対して、$Y \overset{d}{=} X_1 + \dots + X_r$ ($\overset{d}{=}$ は両辺の確率変数が従う分布が等しいことを表す) となることと、<br>
式 (5.12) より以下が成り立つことからわかる

$$
E[X_1] = \frac{q}{p},\:\: V[X_1] = \frac{q}{p^2}
$$

## 負の二項分布の再生性

確率母関数 $G(s) = \left(\frac{p}{1 - qs}\right)^r$ の形より、K$Y_1 \sim NB(r_1,p)$ と $Y_2 \sim NB(r_2,p)$ が独立ならば、<br>
負の二項分布に関しても以下の再生性が成り立つ

$$
Y_1 + Y_2 \sim NB(r_1 + r_2,p)
$$


# 多項分布

## 定義

$K \:(\ge 2)$ 個の結果 $1,\dots,K$ のいづれか1つが起こる試行を考える  
結果 $j \:(1 \le j \le K)$ が起こる確率を $p_{j} \:(p_1 > 0, \dots, p_K >0,p_1 + \cdots + p_K = 1)$ とする  
この試行を独立に $n$ 回行う時、結果 $j$ が起こる回数回数 $Y^{(j)}$ とする  
このとき、$Y := \left(Y^{(1)}, \dots, Y^{(K)}\right)$ は **多項分布** (multinomial distribution) に従い、$M(n;p_1, \dots, p_K)$ と表す  
(常に $Y^{(1)} + \cdots + Y^{(K)} = n$ が成り立つことに注意)

特に $K = 2$ のとき、$Y = \left(Y^{(1)}, Y^{(2)}\right) = \left(Y^{(1)}, n - Y^{(1)}\right) \sim M(n;p_1, 1 - p_1)$ と1対1に対応する $Y^{(1)}$ は<br>
二項分布 $Bin(n, p_1)$ に従うので、多項分布は二項分布の一般化と考えることができる

多項分布 $M(n;p_1, \dots, p_K)$ の確率関数は

$$
P(Y^{(1)} = y^{(1)},\dots, Y^{(K)} = y^{(K)}) = \frac{n!}{y^{(1)}! \cdots y^{(K)}!}p_1^{y^{(1)}} \cdots p_K^{y^{(K)}},\\
y^{(j)} \in \{0,1,\dots,n\}\:(1 \le j \le K), \:\: y^{(1)} + \cdots + y^{(K)} = n
$$

(証明)

独立な $n$ 回の試行のうち、結果 $j$ の回数が $y^{(j)} \:(1 \le j \le K)$ となるような結果の列を考えた時、<br>
そのような特定の列が得られる確率が $p_1^{y^{(1)}} \cdots p_K^{y^{(K)}}$ であり、<br>
またそのような結果の列の総数が以下のようになることからわかる

$$
{}_n C_{y^{(1)}} \times {}_{n - y^{(1)}} C_{y^{(2)}} \times \cdots \times {}_{n - y^{(1)} - \cdots -y^{(K-1)}} C_{y^{(K)}} = \frac{n!}{y^{(1)}! \cdots y^{(K)}!}
$$


## 期待値･分散･共分散と確率母関数

多項分布 $M(n;p_1, \dots, p_K)$ の期待値･分散･共分散と確率母関数は、

$$
E\left[Y^{(j)}\right] = np_j, \:\: V\left[Y^{(j)}\right] = np_j\left(1 - p_j\right),\:\: j = 1,\dots,K \tag{5.14}
$$

$$
\mathrm{Cov} \left[Y^{(j)},Y^{(j')}\right] = - np_jp_{j'},\:\: j \neq j' \tag{5.15}
$$

$$
G(s_1,\dots,s_K) = E\left[s^{Y^{(1)}} \cdots s^{Y^{(K)}} \right] = \left(p_1s_1 + \cdots +  p_Ks_K\right)^n \tag{5.16}
$$

(証明)

これらは、$n = 1$ のときの多項分布 $M(1;p_1, \dots, p_K)$ の期待値･分散･共分散と確率母関数から得られる

$n = 1$ のとき、$X = \left(X^{(1)},\dots, X^{(K)}\right) \sim M(1;p_1, \dots, p_K)$ に対して、

$$
E\left[X^{(j)}\right] = p_j, \:\: V\left[X^{(j)}\right] = p_j\left(1 - p_j\right),\:\: j = 1,\dots,K \tag{5.17}
$$

$$
\mathrm{Cov} \left[X^{(j)},X^{(j')}\right] = - p_jp_{j'},\:\: j \neq j' \tag{5.18}
$$

$$
G(s_1,\dots,s_K) = E\left[s^{X^{(1)}} \cdots s^{X^{(K)}} \right] = p_1s_1 + \cdots +  p_Ks_K \tag{5.19}
$$

これを用いると、一般の多項分布の式 (5.14)、(5.15)、(5.16) は次のようにして得られる  
$Y = \left(Y^{(1)}, \dots, Y^{(K)}\right) \sim M(n;p_1, \dots, p_K)$ は<br>
$X_i = \left(X^{(1)}, \dots, X^{(K)}\right) \overset{iid}{\sim} M(1;p_1, \dots, p_K),\:i = 1,\dots,n$ を用いて、<br>
$Y = X_1 + \cdots + X_n$ と表されている  
つまり、$Y^{(j)} = X_1^{(1)} + \cdots + X_n^{(K)},\:j = 1,\dots,K$ と考えて良い  

これと式 (5.17)、(5.18)、(5.19) を用いれば、式 (5.14)、(5.15)、(5.16) が導ける


## 多項分布の再生性

二項分布と同様の再生性が成り立つことが、確率母関数 (5.16) の形からわかる  
(詳細は省略)
