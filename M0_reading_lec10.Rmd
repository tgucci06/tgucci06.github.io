---
title: "Multi-Class Classification"
author: "谷口友哉"
date: "`r Sys.Date()`"
output:
  rmdformats::downcute:
    code_folding: hide
    self_contained: TRUE
    thumbnails: FALSE
    lightbox: FALSE
    css: style.css
    md_extensions: -ascii_identifiers
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}

---

## Motivation

* 現実世界の問題は、テキスト、音声、画像、生物学的配列など複数のクラスを持つことが多い
* これまで研究されてきたアルゴリズムは、2値分類問題のために設計されていた
* 多クラス分類のアルゴリズムはどのように設計されるか？
  * 2値分類に使われるアルゴリズムを多クラス分類に一般化できるか？
  * 多クラス分類を2値分類に還元できるか？

## Introduction

* これまでの章で検討した分類問題はすべて2値分類を考えていた
* しかし現実の分類問題では、クラスの数が2以上のものがほとんど
  * (例) テキスト文書にトピックを割り当てる問題  
         $\;\;\;\;\:$音声にカテゴリーを割り当てる問題  
         $\;\;\;\;\:$生物学的配列に関数を割り当てる問題など  
  * クラスの数が数百以上になることもある

* 本章では，多クラス分類の問題を扱う
  1. 多クラス分類の学習問題を紹介し、その複数の設定を議論した後、ラデマッハ複雑度の概念を用いて一般化境界を導出
  2. 多クラス分類問題に取り組むための一連のアルゴリズムを説明 (多クラスSVM、決定木、多クラスブースティングなど)
  3. 様々な応用で生じる構造化予測の問題についても簡単に説明
  
## 9.1 Multi-class classification problem

### Notion 

* $\mathcal X$ を入力空間
* $\mathcal Y$ を出力空間
* $\mathcal D$ を $\mathcal X$ 上の未知の分布 ($\mathcal X$ は $\mathcal D$ からi.i.dに抽出)
* $\mathcal Y$ がクラスの有限集合
  * $\mathcal Y = \{1, ... , k\}$ とする mono-label case と、$\mathcal Y = \{-1,+1\}^k$ とする multi-label case を区別する (便宜的に数字で表記)

* mono-label case : 各例は1つのクラスでラベル付けされる
* multi-label case: 複数のクラスでラベル付けされる

* multi-label case は、スポーツ、ビジネス、社会などの複数の異なるトピックでラベル付けされたテキスト文書のケースで説明できる

### Generalization error

* いずれの場合も、学習者は、ラベル付き標本 $S = ((x_1, y_1), ... , (x_m, y_m)) ∈ \left(\mathcal X × \mathcal Y\right)^m$ を受け取る
  * $x_1, ... , x_m$ は$\mathcal D$ に従ってi.i.d.で抽出される
  * $\forall i∈[1,m],\;y_i = f(x_i)$ であり、$f : \mathcal X → \mathcal Y$は対象となるラベリング関数

* 以下では決定論的なシナリオを考える
  * 2.4.1節で述べたように、$\mathcal X×\mathcal Y$ の分布を認める確率的なものに簡単に拡張できる
* $\mathcal X$ を $\mathcal Y$ に写像する関数の仮説集合 $\mathcal H$ が与えられた場合、多クラス分類問題はラベル付き標本 $S$ を用いて、ターゲット $f$ に関して小さな汎化誤差 $R(h)$ を持つ仮説 $h∈\mathcal H$ を見つけること

$$
R(h) = \mathbb E_{x \sim \mathcal D}[1_{h(x)\neq f(x)}] \;\;\; \rm{mono-label\;case}\tag{9.1}
$$

$$
R(h) = \mathbb E_{x \sim \mathcal D}\left[\sum^{k}_{l = 1} 1_{[h(x)]_l\neq [f(x)]_l}\right] \;\;\; \rm{multi-label\;case}\tag{9.2}
$$

* ハミング距離 $d_H$（2つのベクトルの中で異なる対応する成分の数）の概念は、両方の誤差に共通の定式化を与えるために使用することができる

$$
R(h) = \mathbb E_{x \sim \mathcal D}\left[d_H\left(h(x),f(x)\right)\right] \;\;\;\tag{9.3}
$$

* $h∈\mathcal H$ の経験的誤差を $\hat{R}_S(h)$ とし、次のように定義する

$$
\hat{R}_S(h) = \frac{1}{m}\sum^{m}_{i = 1}d_H\left(h(x_i),y_i\right) \tag{9.4}
$$

### Note

* 多クラスの設定では、計算上および学習上の問題がいくつか発生する

1. 多数のクラスを扱うこと (計算上の問題)
    * クラスの数 $k$  は、これから紹介するアルゴリズムの時間的複雑さに直接影響する
    * $k=100$ や $k=1,000$ のような比較的少ないクラス数であっても、実際には使用できないかもしれない

2. 不均衡なクラスの存在
    * ラベル付けされた標本の5％以下のクラスもあれば、データの非常に大きな部分を占めるクラスもある
    * 多クラスの解を定義するために別々の2値分類器が使用されている場合、トレーニングサンプルにわずかしか含まれていない2つのクラスを区別する分類器をトレーニングする必要がある
    * これは小さなサンプルで学習することを意味し、性能の保証ができない
    * また、学習インスタンスの大部分が1つのクラスに属する場合、先に定義した汎化誤差が比較的低いと思われるため、常にそのクラスを返す仮説を提案したくなるかもしれない
    * しかし、このような些細な解は、通常、意図したものではない
    * 代わりに、クラスの各ペアに異なる誤分類の重みを割り当てることで、損失関数を再定式化する必要があるかもしれない

3. クラスの階層化 (クラス間の関係性)
    * (例) 文書分類の場合、世界の政治を扱った文書を不動産を扱った文書に誤分類した場合は、より具体的なラベルである野球ではなくスポーツのラベルを付けた場合よりも、当然ながらペナルティが大きくなる
    * より複雑で有用な多クラス分類法では、クラス間の階層的な関係を考慮し、この階層に応じて損失関数を定義する
    * クラス間の階層的な関係を用いることで、より豊かで複雑な多クラス分類問題となる

## 9.2 Generalization bounds

mono-label case 多クラス分類における、マージンベースの汎化境界を示す

2値の状況では、分類器はしばしばスコアリング関数の符号に基づいて定義される

多クラスの設定では、仮説はスコアリング関数 $h :\mathcal X × \mathcal Y → \mathbb R$ に基づいて定義される

点 $x$ に関連するラベルは、最大のスコア $h(x, y)$ をもたらすものであり、$\mathcal X$ から $\mathcal Y$ への以下の写像を定義

\newcommand{\argmax}{\mathop{\rm arg~max}\limits}
\newcommand{\argmin}{\mathop{\rm arg~min}\limits}

$$
x \mapsto \argmax_{y \in \mathcal Y} \:\:h(x,y)
$$

当然ながら、ラベルを付けた例 $(x, y)$ における関数 $h$ のマージン $\rho_h(x, y)$ は、次のように定義される

$$
\rho_h(x, y) = h(x,y) - \max_{y'\neq y}\,h\left(x,y'\right)
$$

したがって、$h$ が $(x,y)$ を誤分類するのは、$\rho_h(x,y) \le 0$ と同値

$\forall \rho > 0$ において、多クラス分類に対する仮説 $h$ の経験マージン損失を次のように定義できる

$$
\hat{R}_{S,\rho}(h) = \frac{1}{m}\sum^m_{i = 1}\Phi_\rho\left(\rho_h(x_i,y_i)\right) \tag{9.5}
$$

ここで $\Phi_{\rho}$ はマージン損失関数である（定義5.5）

したがって、多クラス分類の経験マージン
損失は、$h$ によって誤分類された訓練点の割合、または正しく分類されたが信頼度が $\rho$ 以下の訓練点の割合によって抑えられる

$$
\hat{R}_{S,\rho}(h) = \frac{1}{m}\sum^m_{i = 1}1_{\rho_h(x_i,y_i) \le \rho} \tag{9.6}
$$

### Theorem 9.2 (Margin bound for multi-class classification) 

## Conclusion

* One-vs-allアプローチが最も広く使われている
* 他のアプローチが優れているという明確な経験的証拠はない (Rifkin and Klautau, 2004)
  * 比較的大きな error rate (誤分類率) を持つ小さなデータセットの場合を除く
* 大規模な構造化多クラス問題：しばしばランキング問題として扱われる（10章のランキングを参照）

